{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the ONNX file\n",
    "model = rt.InferenceSession('model.onnx')\n",
    "input_name = model.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.nn.Sequential(\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_of_dicom_field_as_int(x):\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image(img, window_center, window_width, intercept, slope):\n",
    "    \"\"\"\n",
    "    Get windowed image from dicom\n",
    "\n",
    "    Inputs:\n",
    "        - original image\n",
    "        - window_center\n",
    "        - window_width\n",
    "        - intercept\n",
    "        - slope\n",
    "    \"\"\"\n",
    "    img = img * slope + intercept\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    img[img < img_min] = img_min\n",
    "    img[img > img_max] = img_max\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_text_on_dicom(image_path, text):\n",
    "    # Load the DICOM image\n",
    "    ds = pydicom.dcmread(image_path)\n",
    "\n",
    "    # Apply VOI LUT to get the actual pixel data\n",
    "    pixel_data = np.zeros((512,512))\n",
    "\n",
    "    # Create a PIL image from the pixel data\n",
    "    img = Image.fromarray(pixel_data)\n",
    "\n",
    "    # Draw text on the image\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((10, 10), text, fill=\"red\")\n",
    "\n",
    "    # Save the modified image back to DICOM format\n",
    "    img_array = np.array(img)\n",
    "    ds.PixelData = img_array.tobytes()\n",
    "    # ds.save_as(image_path.replace('.dcm', '_overlay.dcm'))\n",
    "\n",
    "    return Image.fromarray(ds.pixel_array).convert(\"RGB\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dcm):\n",
    "\n",
    "    metadata = {\n",
    "        \"intercept\": dcm.RescaleIntercept,\n",
    "        \"slope\": dcm.RescaleSlope,\n",
    "    }\n",
    "\n",
    "    images = []\n",
    "    for window_center, window_width in [[40, 80], [80, 200], [600, 2800]]:\n",
    "        metadata[\"window_center\"] = window_center\n",
    "        metadata[\"window_width\"] = window_width\n",
    "        metadata = {k: get_first_of_dicom_field_as_int(v) for k, v in metadata.items()}\n",
    "        # print(\"Shp:\", img_dicom.pixel_array.shape)\n",
    "        img = window_image(dcm.pixel_array, **metadata)\n",
    "        images.append(img)\n",
    "\n",
    "    stacked = np.stack(images).astype(np.float32)\n",
    "    stacked = stacked[:,:,:,np.newaxis]\n",
    "    stacked = np.transpose(stacked, (3, 0, 1, 2))\n",
    "    return torch.from_numpy(stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file):\n",
    "    dcm = pydicom.dcmread(file)\n",
    "    input = preprocess(dcm)\n",
    "    input = scripted_transforms(input).cpu().numpy()\n",
    "\n",
    "    # Execute the inference via ONNX Runtime\n",
    "    outputs = model.run(None, {input_name: input})\n",
    "\n",
    "    outputs = np.argmax(outputs[0])\n",
    "\n",
    "    text = \"Positive\" if outputs == 1 else \"Negative\"\n",
    "\n",
    "    # Normalize the background (input) image\n",
    "    dcmpixel = dcm.pixel_array\n",
    "    background = 255 * ( 1.0 / dcmpixel.max() * (dcmpixel - dcmpixel.min()) )\n",
    "    background = background.astype(np.ubyte)\n",
    "    background_image = Image.fromarray(background).convert(\"RGB\")\n",
    "\n",
    "    overlay_image = overlay_text_on_dicom(file, text)\n",
    "    # overlay_image = ImageOps.colorize(overlay_image, black=\"black\", white='yellow')\n",
    "\n",
    "\n",
    "    # Blend the two images\n",
    "    final_image = Image.blend(overlay_image, background_image, 0.75)\n",
    "    final_array = np.array(final_image).astype(np.uint8) \n",
    "\n",
    "    print(final_array.shape)\n",
    "\n",
    "    return final_array\n",
    "\n",
    "    # # Write the final image back to a new DICOM (color) image \n",
    "    # dcm.SeriesInstanceUID = series_uid\n",
    "    # dcm.SOPInstanceUID = generate_uid()\n",
    "    # dcm.SeriesNumber = dcm.SeriesNumber + settings[\"series_offset\"]\n",
    "    # dcm.file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian\n",
    "    # dcm.Rows = final_image.height\n",
    "    # dcm.Columns = final_image.width\n",
    "    # dcm.PhotometricInterpretation = \"RGB\"\n",
    "    # dcm.SamplesPerPixel = 3\n",
    "    # dcm.BitsStored = 8\n",
    "    # dcm.BitsAllocated = 8\n",
    "    # dcm.HighBit = 7\n",
    "    # dcm.PixelRepresentation = 0\n",
    "    # dcm.PixelData = final_array.tobytes()\n",
    "    # dcm.SeriesDescription = \"SEG(\" + dcm.SeriesDescription + \")\"\n",
    "    # dcm.save_as(dcm_file_out)  \n",
    "\n",
    "    # return outputs\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_image('/dataNAS/people/arogya/projects/ich-evaluation/outputs/3dq-test-data/any/ID_27fe0a13c6/ID_459b77eea.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "DIR = '/dataNAS/people/arogya/projects/ich-evaluation/outputs/3dq-test-data/any/ID_27fe0a13c6'\n",
    "images = os.listdir(DIR)\n",
    "for image in images:\n",
    "    out = process_image(f'{DIR}/{image}')\n",
    "    # out[0].save_as(\"overlayed.dcm\")\n",
    "    # print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ich-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
